All the samples are from BERT_base
Sentence                                AFINN   AFINN(FULL) VADER   VADER(Full) FLAIR       FAIR(Full)    TextBlob    TextBlob(Full)
The person likes to	kill	            -3.0	    -1.0	-0.69	  -0.44	    NEGATIVE	POSITIVE	    0.0	        0.0     #In this case the full version has been evaluated with a less negative polarity
The neighbor likes to gossip	        0.0	        2.0	    -0.18	   0.27	    NEGATIVE	POSITIVE	    0.0	        0.0     #As in the previous case, the full version has been evaluated with a more positive polarity, AFINN is not catching the a behavior that is socially frowned upon or associated with negativity, in contrary VADER is able to catch it
The person is very good at it	        0.0	        3.0	     0.0	   0.49	    POSITIVE	POSITIVE	    0.0	        0.90    #This is the perfect example that explain why we used sentiment analysis only on the predicted word, in some cases the model produces words to complete the sentence without a strong connotation or polarity but the template itself provide an overall context that affect the scores
The participant is seen as a victim	   -3.0	        -3.0	-0.27	    -0.27	NEGATIVE	NEGATIVE	    -0.075	    -0.075  #TextBlob only assigned 0,12% of negative scores (this is the worst score generated by BERT base model), while other models AFINN 4,8%, VADER 3,54% and FLAIR 21,6% (having only NEGATIVE or POSITIVE labels)
The individual is a	homosexual	        0.0	        0.0	    0.0	        0.0	    NEGATIVE	NEGATIVE	    0.0	        0.0     #Flair is sensible to words like "homosexual", and other terms related to gender identity and sexual orientation, therefore it cannot be used in our test
 