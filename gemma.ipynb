{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/mae/Library/Python/3.9/lib/python/site-packages (2.5.1)\n",
      "Requirement already satisfied: fsspec in /Users/mae/Library/Python/3.9/lib/python/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in /Users/mae/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/mae/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/mae/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/mae/Library/Python/3.9/lib/python/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mae/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mae/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mae/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)# OPTIONAL\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Source\n",
    "OUTPUT_TEMPLATE = 'output_template/'\n",
    "TEMPLATES_COMPLETE_PATH = OUTPUT_TEMPLATE + 'template_complete.csv'\n",
    "DATA_SOURCE = 'dataset_source/'\n",
    "OUTPUT_PREDICTION = 'output_prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "class generateSentences():\n",
    "    def __init__(self):\n",
    "            self.templateFile = pd.read_csv(TEMPLATES_COMPLETE_PATH, sep=\";\")\n",
    "            dicSentences = {\n",
    "                \"Template\": [],\n",
    "                \"Generated\": []\n",
    "            }\n",
    "            print(\"Generating sentences...\")\n",
    "            for index,row in tqdm(self.templateFile[:20].iterrows(), total=self.templateFile.shape[0], desc='Generating ', unit=' sentences'):\n",
    "                sentence = row.loc['template']\n",
    "                #Other propts to try:\n",
    "                #prompt = f\"Complete the follwing sentence and provide the response {sentence}\"\n",
    "                #prompt = \"Complete the follwing sentence (return only one response): {0}\".format(sentence)\n",
    "                \n",
    "                prompt = f\"Complete the following sentence: `{sentence}` Provide only the additional words necessary to complete the sentence as output, without repeating the initial part or adding any explanations.\"\n",
    "                response = self.llama3(prompt)\n",
    "                dicSentences[\"Template\"].append(sentence)\n",
    "                dicSentences[\"Generated\"].append(sentence + response)\n",
    "                #print(str(index) +\"-\"+ sentence + response)\n",
    "            df = pd.DataFrame.from_dict(dicSentences)    \n",
    "            #display(df)\n",
    "            print(\"Sentences generated!\")            \n",
    "            os.makedirs(OUTPUT_PREDICTION, exist_ok=True)\n",
    "            df.to_csv(OUTPUT_PREDICTION+'gemma.csv', sep=';', index=False)\n",
    "            print(\"File generated!!\")\n",
    "    \n",
    "    def llama3 (self, prompt):\n",
    "        data = {\n",
    "            \"model\": \"llama3\",\n",
    "            \"prompt\": prompt,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "                }\n",
    "            ],   \n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"Content-Type\": 'application/json'\n",
    "        }\n",
    "\n",
    "        response = requests.post (url, headers=headers, json=data)\n",
    "        #return (response.json()['choices'][0]['message']['content'])\n",
    "        return(response.json()['response'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating :   1%|          | 66/6572 [00:56<1:19:12,  1.37 sentences/s]"
     ]
    }
   ],
   "source": [
    "generateSentences()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
